{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a._k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        if k is not None:\n",
    "            self._k=k\n",
    "        else:\n",
    "            self._k=sum(self.rows)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:#controlla se si può fare quella mossa e la fa fare\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_1(initial_state):\n",
    "    new_state = deepcopy(initial_state)\n",
    "    righe_non_zero = [(indice, numero) for indice, numero in enumerate(new_state.rows) if numero != 0]\n",
    "    numero_righe_non_zero = len(righe_non_zero)\n",
    "    indice, bstn = righe_non_zero[0]\n",
    "\n",
    "    if numero_righe_non_zero == 1 and bstn != 1:\n",
    "        #if there is 1 row left I make a different move, so i don't use evolutaionary alghoritm\n",
    "        return Nimply(indice, bstn - 1)\n",
    "    else:\n",
    "        return optimal(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_2(initial_state):\n",
    "    return optimal(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_3(initial_state):\n",
    "    analysis = analize(initial_state)\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_array_from_function(n, initial_state):\n",
    "    #here i generate the population, so it is composed by dstinct member\n",
    "    unique_set = set()\n",
    "    unique_array = []\n",
    "\n",
    "    while len(unique_set) < n:\n",
    "        value = pure_random(initial_state)\n",
    "        _, m = value\n",
    "        if  value not in unique_set and m <= initial_state._k:\n",
    "            unique_set.add(value)\n",
    "            unique_array.append(value)\n",
    "            \n",
    "    return unique_array\n",
    "\n",
    "def strategy_4(initial_state):\n",
    "    actual_nimsum = nim_sum(initial_state)\n",
    "    possible_solutions = generate_unique_array_from_function(sum(initial_state.rows), initial_state)\n",
    "    min = sys.maxsize\n",
    "    min_sol = initial_state\n",
    "    for sol in possible_solutions:\n",
    "        tmp = deepcopy(initial_state)\n",
    "        tmp.nimming(sol)\n",
    "        if nim_sum(tmp) == actual_nimsum:\n",
    "            return sol\n",
    "        if abs(actual_nimsum - nim_sum(tmp)) < min:\n",
    "            min = abs(actual_nimsum - nim_sum(tmp))\n",
    "            min_sol = sol\n",
    "    return min_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_5(initial_state):\n",
    "    return gabriele(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_6(initial_state):\n",
    "    row = initial_state.rows.index(max(initial_state.rows))\n",
    "    return Nimply(row,random.randint(1, initial_state.rows[row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_nim(nim, p1, p2):\n",
    "    player = 0\n",
    "    while nim:\n",
    "        if player == 0:\n",
    "            ply = p1(nim)\n",
    "        else:\n",
    "            ply = p2(nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player\n",
    "    \n",
    "    return player\n",
    "\n",
    "def evaluate_strategy(strategy):\n",
    "    win_counter = 0\n",
    "    enemies = [optimal, pure_random]\n",
    "\n",
    "    for e in enemies:\n",
    "        for i in range(25):\n",
    "            nim = Nim(5)\n",
    "            winner = play_nim(nim, strategy, e)\n",
    "            if winner == 0:\n",
    "                win_counter += 1\n",
    "\n",
    "    for e in enemies:\n",
    "        for i in range(25):\n",
    "            nim = Nim(5)\n",
    "            winner = play_nim(nim, e, strategy)\n",
    "            if winner == 1:\n",
    "                win_counter += 1\n",
    "                        \n",
    "    return win_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_random_choice(weights):\n",
    "    pesi_normalizzati = weights - np.min(weights)\n",
    "    total_peso = np.sum(pesi_normalizzati)\n",
    "    probabilita_normalizzate = pesi_normalizzati / total_peso\n",
    "    indice_selezionato = np.random.choice(len(weights), p=probabilita_normalizzate)    \n",
    "    return indice_selezionato\n",
    "\n",
    "def weight_mean(weights, fitness):\n",
    "    weight_summed = np.sum(weights * fitness)\n",
    "    sum_weight = np.sum(weights)\n",
    "    \n",
    "    # Calcola la media pesata\n",
    "    mean = weight_summed / sum_weight\n",
    "    return mean\n",
    "\n",
    "def fitness(x, tmp_array):\n",
    "    if x.ndim == 1:\n",
    "        result_array = np.zeros((1,))\n",
    "        result_array[0] = weight_mean(x, tmp_array)\n",
    "    else:\n",
    "        result_array = np.zeros((x.shape[0],))\n",
    "        for i in range(x.shape[0]): \n",
    "            result_array[i]= weight_mean(x[i], tmp_array)\n",
    "   \n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1 + λ) - ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_plus_strategy(strategies, σ=None, λ=20):\n",
    "    strat_evals = []\n",
    "    for s in strategies:\n",
    "        strat_evals.append(evaluate_strategy(s))\n",
    "\n",
    "    sol_dim = len(strategies) + 1 if σ is None else len(strategies)     #if σ is None we use adptive strategy\n",
    "    solution = abs(np.random.random(sol_dim)) \n",
    "    best_so_far = np.copy(solution)\n",
    "\n",
    "    for _ in range(100000 // λ):\n",
    "        if σ is None:\n",
    "            \n",
    "            # offspring <- select λ random points mutating the current solution\n",
    "            offspring = abs(np.random.normal(loc=0, scale=solution[sol_dim - 1], size=(λ, sol_dim)) + solution)\n",
    "            # evaluate and select best\n",
    "            evals = fitness(offspring[:,:sol_dim - 1], strat_evals)\n",
    "            solution = offspring[np.argmax(evals)]\n",
    "    \n",
    "            if fitness(best_so_far[:sol_dim - 1], strat_evals) < fitness(solution[:sol_dim - 1], strat_evals):\n",
    "                best_so_far = np.copy(solution)\n",
    "        else:\n",
    "            # offspring <- select λ random points mutating the current solution\n",
    "            offspring = abs(np.random.normal(loc=0, scale=σ, size=(λ, sol_dim)) + solution)\n",
    "            # evaluate and select best\n",
    "            evals = fitness(offspring, strat_evals)\n",
    "            solution = offspring[np.argmax(evals)]\n",
    "        \n",
    "            if fitness(best_so_far, strat_evals) < fitness(solution, strat_evals):\n",
    "                best_so_far = np.copy(solution)\n",
    "    \n",
    "    if σ is None:\n",
    "        best_σ = best_so_far[sol_dim - 1]\n",
    "        return best_so_far[:sol_dim - 1], best_σ\n",
    "    \n",
    "    return best_so_far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1, λ) - ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_comma_strategy(strategies, σ=None, λ=20):\n",
    "    strat_evals = []\n",
    "    for s in strategies:\n",
    "        strat_evals.append(evaluate_strategy(s))\n",
    "\n",
    "    sol_dim = len(strategies) + 1 if σ is None else len(strategies)     #if σ is None we use adptive strategy\n",
    "    solution = abs(np.random.random(sol_dim)) \n",
    "    best_so_far = np.copy(solution)\n",
    "\n",
    "    for _ in range(100000 // λ):\n",
    "        if σ is None:\n",
    "            # offspring <- select λ random points mutating the current solution\n",
    "            offspring = abs(np.random.normal(loc=0, scale=solution[sol_dim - 1], size=(λ, sol_dim)) + solution)\n",
    "            # evaluate and select best\n",
    "            evals = fitness(offspring[:,:sol_dim - 1], strat_evals)\n",
    "            solution = offspring[np.argmax(evals)]\n",
    "        else:\n",
    "            # offspring <- select λ random points mutating the current solution\n",
    "            offspring = abs(np.random.normal(loc=0, scale=σ, size=(λ, sol_dim)) + solution)\n",
    "            # evaluate and select best\n",
    "            evals = fitness(offspring, strat_evals)\n",
    "            solution = offspring[np.argmax(evals)]\n",
    "        \n",
    "        best_so_far = np.copy(solution)\n",
    "    \n",
    "    if σ is None:\n",
    "        best_σ = best_so_far[sol_dim - 1]\n",
    "        return best_so_far[:sol_dim - 1], best_σ\n",
    "    \n",
    "    return best_so_far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(strategies, weights):\n",
    "    strategy = strategies[weighted_random_choice(weights)]\n",
    "    return evaluate_strategy(strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- (1 + λ) - ES:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tσ = 1.000e+00\t59 wins\n",
      "\tσ = 1.000e-01\t69 wins\n",
      "\tσ = 1.000e-02\t75 wins\n",
      "\tσ = 1.000e-03\t62 wins\n",
      "\tσ = 1.000e-04\t46 wins\n",
      "- (1, λ) - ES:\n",
      "\tσ = 1.000e+00\t67 wins\n",
      "\tσ = 1.000e-01\t64 wins\n",
      "\tσ = 1.000e-02\t65 wins\n",
      "\tσ = 1.000e-03\t62 wins\n",
      "\tσ = 1.000e-04\t62 wins\n",
      "- (1 + λ) - ES (adaptive):\n",
      "\tσ = 7.441e-02\t69 wins\n",
      "- (1, λ) - ES (adaptive):\n",
      "\tσ = 2.339e-67\t69 wins\n"
     ]
    }
   ],
   "source": [
    "sigmas = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "strategies = [strategy_1, strategy_2, strategy_3, strategy_4, strategy_5, strategy_6]\n",
    "\n",
    "## (1 + λ) - ES (no adaptive)\n",
    "print('- (1 + λ) - ES:')\n",
    "for s in sigmas:\n",
    "    weights = es_plus_strategy(strategies, σ=s)\n",
    "    print('\\tσ = {0:.3e}\\t{1} wins'.format(s, test(strategies, weights)))\n",
    "\n",
    "## (1, λ) - ES (no adaptive)\n",
    "print('- (1, λ) - ES:')\n",
    "for s in sigmas:\n",
    "    weights = es_comma_strategy(strategies, σ=s)\n",
    "    print('\\tσ = {0:.3e}\\t{1} wins'.format(s, test(strategies, weights)))\n",
    "\n",
    "## (1 + λ) - ES (adaptive)\n",
    "weights, σ = es_plus_strategy(strategies,λ=100)\n",
    "print('- (1 + λ) - ES (adaptive):')\n",
    "print('\\tσ = {0:.3e}\\t{1} wins'.format(σ, test(strategies, weights)))\n",
    "\n",
    "## (1, λ) - ES (adaptive)\n",
    "weights, σ= es_comma_strategy(strategies,λ=100)\n",
    "print('- (1, λ) - ES (adaptive):')\n",
    "print('\\tσ = {0:.3e}\\t{1} wins'.format(σ, test(strategies, weights)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
